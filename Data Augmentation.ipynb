{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d166200-53c8-4008-8fb7-fa6e037baaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import string as st\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab377679-67d6-4434-b4ea-f9af2a606ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorflow_shutup():\n",
    "    \"\"\"\n",
    "    Make Tensorflow less verbose\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "        # noinspection PyPackageRequirements\n",
    "        from tensorflow.python.util import deprecation\n",
    "\n",
    "        tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "        # Monkey patching deprecation utils to shut it up! Maybe good idea to disable this once after upgrade\n",
    "        # noinspection PyUnusedLocal\n",
    "        def deprecated(date, instructions, warn_once=True):  # pylint: disable=unused-argument\n",
    "            def deprecated_wrapper(func):\n",
    "                return func\n",
    "            return deprecated_wrapper\n",
    "\n",
    "        deprecation.deprecated = deprecated\n",
    "\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "tensorflow_shutup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e69d836d-4246-4339-8a46-b7a195874864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data augmentation model\n",
    "data_augmentation = Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.1, fill_mode='nearest'),\n",
    "    layers.RandomZoom(height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2), fill_mode='nearest')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9194a5ce-3c6d-48dc-b2a2-8d14c47bb4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the images from the asl_dataset and do augmentation for all classes\n",
    "labels = st.digits\n",
    "iters = 800\n",
    "path = os.path.join('asl_alphabet_train', 'asl_alphabet_train')\n",
    "for label in labels:\n",
    "    imgs = os.listdir(os.path.join(path, label))\n",
    "    data = []\n",
    "    for img_name in imgs:\n",
    "        img = Image.open(os.path.join(path, label, img_name)).resize((100, 100))\n",
    "        arr = np.asarray(img)\n",
    "        data.append(arr)\n",
    "    data = np.array(data) # Original images of the dataset as arrays\n",
    "    ind1 = 0\n",
    "    while len(imgs) < iters:   \n",
    "        aug_data = data_augmentation(data)\n",
    "        aug_data = np.array(aug_data)\n",
    "        for ind2, aug_d in enumerate(aug_data, 1):\n",
    "            img = Image.fromarray(aug_d.astype('uint8'))\n",
    "            img.save(os.path.join(path, label, '{}.jpeg'.format(str(ind1) + str(ind2))))\n",
    "        imgs = os.listdir(os.path.join(path, label))\n",
    "        ind1 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0a9f4c6-0f7f-48b3-a3a4-8add605a5b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image contouring\n",
    "labels = st.digits + st.ascii_lowercase\n",
    "for label in labels:\n",
    "    imgs = os.listdir(os.path.join('asl_dataset', label))\n",
    "    targ_dir = os.path.join('seg dataset', label)\n",
    "    os.mkdir(targ_dir)\n",
    "    for img_name in imgs:\n",
    "        img = cv2.imread((os.path.join('asl_dataset', label, img_name)))\n",
    "        # convert img to grey\n",
    "        img_grey = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        # set a thresh\n",
    "        thresh = 40\n",
    "        # get threshold image\n",
    "        ret,thresh_img = cv2.threshold(img_grey, thresh, 255, cv2.THRESH_BINARY)\n",
    "        # find contours\n",
    "        contours, hierarchy = cv2.findContours(thresh_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # create an empty image for contours\n",
    "        img_contours = np.zeros(img.shape)\n",
    "        # draw the contours on the empty image\n",
    "        cv2.drawContours(img_contours, contours, -1, (0,255,0), 3)\n",
    "        # Fill the polygon with white\n",
    "        cv2.fillPoly(img_contours, pts=contours, color=(255,255,255))\n",
    "        # Save the image\n",
    "        cv2.imwrite(os.path.join(targ_dir, img_name), img_contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2596f7-8ea8-4194-ab58-b65a32e1ae0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
